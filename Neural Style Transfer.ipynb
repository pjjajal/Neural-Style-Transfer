{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599876904423",
   "display_name": "Python 3.8.3 64-bit ('CoreEnv': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as display\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Num GPUs Available:  1\n"
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_image(image,3)\n",
    "    image = tf.image.convert_image_dtype(image,tf.float32)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(image, input_shape):\n",
    "    # processed_image = tf.keras.applications.vgg19.preprocess_input(image*255)\n",
    "    processed_image = tf.image.resize(image, size = input_shape)\n",
    "    # processed_image = tf.image.resize(processed_image, size = (224,224))\n",
    "    processed_image = tf.expand_dims(processed_image,0)\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(generated_output, content_outputs):\n",
    "    loss = 0.5*tf.reduce_sum(tf.square(tf.subtract(content_outputs,generated_output)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_matrix(input):\n",
    "    output = tf.reshape(input,(-1,input.shape[-1]))\n",
    "    output = tf.matmul(output,output,transpose_a=True)\n",
    "    # Alternate implementation\n",
    "    # output = tf.einsum('bijc,bijd->bcd',input,input)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def style_loss(generated_outputs,style_gram,weights):\n",
    "    for generated_output,weight,gram_style_image in zip(generated_outputs,weights,style_gram):\n",
    "        nh,nw,nc = generated_output.shape[1:]\n",
    "        gram_generated_im = gram_matrix(generated_output)\n",
    "        # gram_style_image = gram_matrix(style_output) \n",
    "        loss = weight*(1/(4*(nh*nw*nc)**2))*tf.reduce_sum(tf.square(tf.subtract(gram_generated_im,gram_style_image)))\n",
    "        # loss += weight*tf.reduce_sum(tf.square(tf.subtract(gram_style_image,gram_generated_im)))\n",
    "        # print('Style Loss: {}'.format(loss))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_loss(content_loss, style_loss, alpha, beta):\n",
    "    total = tf.add(tf.multiply(alpha,content_loss), tf.multiply(beta,style_loss))\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradients(StyleTransModel,gen_image,style_gram,content_outputs,weights,alpha,beta):\n",
    "    with tf.GradientTape() as tape:\n",
    "        output_gen = StyleTransModel(gen_image)\n",
    "        # loss = 0.5*tf.reduce_sum(tf.square(tf.subtract(output_content,output_gen)))\n",
    "        cont_loss = content_loss(output_gen[-1],content_outputs)\n",
    "        sty_loss = style_loss(output_gen[:-1],style_gram,weights)\n",
    "        loss_total = total_loss(cont_loss,sty_loss,alpha,beta)\n",
    "    print(loss_total)\n",
    "    return tape.gradient(loss_total,X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StyleTransferModel(tf.keras.Model):\n",
    "    def __init__(self,content_path,style_path,input_shape,style_layers,content_layers):\n",
    "        super(StyleTransferModel, self).__init__()\n",
    "        self.model_input_shape = input_shape\n",
    "        self.content_image = load_image(content_path)\n",
    "        self.style_image = load_image(style_path)\n",
    "        self.resized_content_image = resize_image(self.content_image, self.model_input_shape[:-1])\n",
    "        self.resized_style_image = resize_image(self.style_image,self.model_input_shape[:-1])\n",
    "        vgg = tf.keras.applications.VGG19(include_top=False,pooling='avg', input_shape=input_shape,weights='imagenet')\n",
    "        vgg.trainable = False\n",
    "        self.model = keras.Model([vgg.input],[vgg.get_layer(layer).output for layer in (style_layers + content_layers)])\n",
    "    \n",
    "    def style_outputs(self):\n",
    "        output = self.call(self.resized_style_image)[:-1]\n",
    "        return output\n",
    "\n",
    "    def content_outputs(self):\n",
    "        output = self.call(self.resized_content_image)[-1]\n",
    "        return output\n",
    "\n",
    "    def generate_image(self):\n",
    "        generated_image = tf.image.resize(self.content_image, size = self.model_input_shape[:-1])\n",
    "        generated_image = tf.expand_dims(generated_image,0)\n",
    "        return generated_image\n",
    "\n",
    "    def call(self, inputs):\n",
    "        processed_input = tf.keras.applications.vgg19.preprocess_input(inputs*255)\n",
    "        outputs = self.model(processed_input)\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_path = tf.keras.utils.get_file('woodstock.jpg','https://hips.hearstapps.com/hmg-prod.s3.amazonaws.com/images/gettyimages-96264452-1513966019.jpg?crop=1xw:1xh;center,top&resize=980:*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "style_path = tf.keras.utils.get_file('Bather with Beach Ball, 1932 by Pablo Picasso.jpg','https://www.pablopicasso.net/images/Bather%20with%20Beach%20Ball%20Picasso.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "content_layers = ['block4_conv2']\n",
    "style_layers =['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
    "weights = [0.2,0.2,0.2,0.2,0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = StyleTransferModel(content_path,style_path,(512,512,3),style_layers,content_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_outputs = model.content_outputs()\n",
    "style_outputs = model.style_outputs()\n",
    "style_gram = [gram_matrix(output) for output in style_outputs]\n",
    "generated_image = model.generate_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.Variable(generated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch:0/10\n\ntf.Tensor(4295051.0, shape=(), dtype=float32)\ntf.Tensor(90363080.0, shape=(), dtype=float32)\ntf.Tensor(43673280.0, shape=(), dtype=float32)\ntf.Tensor(37932228.0, shape=(), dtype=float32)\ntf.Tensor(36847440.0, shape=(), dtype=float32)\ntf.Tensor(36379824.0, shape=(), dtype=float32)\ntf.Tensor(35718540.0, shape=(), dtype=float32)\ntf.Tensor(34953044.0, shape=(), dtype=float32)\ntf.Tensor(34375908.0, shape=(), dtype=float32)\ntf.Tensor(33740844.0, shape=(), dtype=float32)\ntf.Tensor(33036496.0, shape=(), dtype=float32)\ntf.Tensor(32327040.0, shape=(), dtype=float32)\ntf.Tensor(31666162.0, shape=(), dtype=float32)\ntf.Tensor(31009706.0, shape=(), dtype=float32)\ntf.Tensor(30362748.0, shape=(), dtype=float32)\ntf.Tensor(29766288.0, shape=(), dtype=float32)\ntf.Tensor(29151382.0, shape=(), dtype=float32)\ntf.Tensor(28519486.0, shape=(), dtype=float32)\ntf.Tensor(27914704.0, shape=(), dtype=float32)\ntf.Tensor(27345564.0, shape=(), dtype=float32)\ntf.Tensor(26800878.0, shape=(), dtype=float32)\ntf.Tensor(26284382.0, shape=(), dtype=float32)\ntf.Tensor(25787666.0, shape=(), dtype=float32)\ntf.Tensor(25317318.0, shape=(), dtype=float32)\ntf.Tensor(24862716.0, shape=(), dtype=float32)\ntf.Tensor(24412096.0, shape=(), dtype=float32)\ntf.Tensor(23976284.0, shape=(), dtype=float32)\ntf.Tensor(23561456.0, shape=(), dtype=float32)\ntf.Tensor(23175198.0, shape=(), dtype=float32)\ntf.Tensor(22801616.0, shape=(), dtype=float32)\ntf.Tensor(22427972.0, shape=(), dtype=float32)\ntf.Tensor(22064304.0, shape=(), dtype=float32)\ntf.Tensor(21718388.0, shape=(), dtype=float32)\ntf.Tensor(21392368.0, shape=(), dtype=float32)\ntf.Tensor(21072088.0, shape=(), dtype=float32)\ntf.Tensor(20757412.0, shape=(), dtype=float32)\ntf.Tensor(20451082.0, shape=(), dtype=float32)\ntf.Tensor(20160824.0, shape=(), dtype=float32)\ntf.Tensor(19883268.0, shape=(), dtype=float32)\ntf.Tensor(19603792.0, shape=(), dtype=float32)\ntf.Tensor(19325204.0, shape=(), dtype=float32)\ntf.Tensor(19050368.0, shape=(), dtype=float32)\ntf.Tensor(18782816.0, shape=(), dtype=float32)\ntf.Tensor(18521398.0, shape=(), dtype=float32)\ntf.Tensor(18264736.0, shape=(), dtype=float32)\ntf.Tensor(18014902.0, shape=(), dtype=float32)\ntf.Tensor(17774616.0, shape=(), dtype=float32)\ntf.Tensor(17542592.0, shape=(), dtype=float32)\ntf.Tensor(17316950.0, shape=(), dtype=float32)\ntf.Tensor(17093482.0, shape=(), dtype=float32)\ntf.Tensor(16871204.0, shape=(), dtype=float32)\ntf.Tensor(16646322.0, shape=(), dtype=float32)\ntf.Tensor(16422645.0, shape=(), dtype=float32)\ntf.Tensor(16215930.0, shape=(), dtype=float32)\ntf.Tensor(16023126.0, shape=(), dtype=float32)\ntf.Tensor(15839136.0, shape=(), dtype=float32)\ntf.Tensor(15660018.0, shape=(), dtype=float32)\ntf.Tensor(15478534.0, shape=(), dtype=float32)\ntf.Tensor(15290673.0, shape=(), dtype=float32)\ntf.Tensor(15102296.0, shape=(), dtype=float32)\ntf.Tensor(14920559.0, shape=(), dtype=float32)\ntf.Tensor(14746359.0, shape=(), dtype=float32)\ntf.Tensor(14574670.0, shape=(), dtype=float32)\ntf.Tensor(14402866.0, shape=(), dtype=float32)\ntf.Tensor(14232760.0, shape=(), dtype=float32)\ntf.Tensor(14068396.0, shape=(), dtype=float32)\ntf.Tensor(13908384.0, shape=(), dtype=float32)\ntf.Tensor(13749864.0, shape=(), dtype=float32)\ntf.Tensor(13598522.0, shape=(), dtype=float32)\ntf.Tensor(13453238.0, shape=(), dtype=float32)\ntf.Tensor(13308790.0, shape=(), dtype=float32)\ntf.Tensor(13162546.0, shape=(), dtype=float32)\ntf.Tensor(13017057.0, shape=(), dtype=float32)\ntf.Tensor(12871838.0, shape=(), dtype=float32)\ntf.Tensor(12733128.0, shape=(), dtype=float32)\ntf.Tensor(12602475.0, shape=(), dtype=float32)\ntf.Tensor(12476169.0, shape=(), dtype=float32)\ntf.Tensor(12351765.0, shape=(), dtype=float32)\ntf.Tensor(12230692.0, shape=(), dtype=float32)\ntf.Tensor(12113335.0, shape=(), dtype=float32)\ntf.Tensor(11993942.0, shape=(), dtype=float32)\ntf.Tensor(11872868.0, shape=(), dtype=float32)\ntf.Tensor(11756618.0, shape=(), dtype=float32)\ntf.Tensor(11642775.0, shape=(), dtype=float32)\ntf.Tensor(11529717.0, shape=(), dtype=float32)\ntf.Tensor(11414623.0, shape=(), dtype=float32)\ntf.Tensor(11299096.0, shape=(), dtype=float32)\ntf.Tensor(11185599.0, shape=(), dtype=float32)\ntf.Tensor(11074580.0, shape=(), dtype=float32)\ntf.Tensor(10969850.0, shape=(), dtype=float32)\ntf.Tensor(10869318.0, shape=(), dtype=float32)\ntf.Tensor(10769856.0, shape=(), dtype=float32)\ntf.Tensor(10671867.0, shape=(), dtype=float32)\ntf.Tensor(10573244.0, shape=(), dtype=float32)\ntf.Tensor(10473513.0, shape=(), dtype=float32)\ntf.Tensor(10375950.0, shape=(), dtype=float32)\ntf.Tensor(10286000.0, shape=(), dtype=float32)\ntf.Tensor(10200267.0, shape=(), dtype=float32)\ntf.Tensor(10115096.0, shape=(), dtype=float32)\ntf.Tensor(10027235.0, shape=(), dtype=float32)\nEpoch:1/10\n\ntf.Tensor(9940685.0, shape=(), dtype=float32)\ntf.Tensor(9856670.0, shape=(), dtype=float32)\ntf.Tensor(9772270.0, shape=(), dtype=float32)\ntf.Tensor(9686630.0, shape=(), dtype=float32)\ntf.Tensor(9605879.0, shape=(), dtype=float32)\ntf.Tensor(9532258.0, shape=(), dtype=float32)\ntf.Tensor(9459508.0, shape=(), dtype=float32)\ntf.Tensor(9385712.0, shape=(), dtype=float32)\ntf.Tensor(9314706.0, shape=(), dtype=float32)\ntf.Tensor(9245817.0, shape=(), dtype=float32)\ntf.Tensor(9174352.0, shape=(), dtype=float32)\ntf.Tensor(9098963.0, shape=(), dtype=float32)\ntf.Tensor(9024590.0, shape=(), dtype=float32)\ntf.Tensor(8956457.0, shape=(), dtype=float32)\ntf.Tensor(8893524.0, shape=(), dtype=float32)\ntf.Tensor(8831950.0, shape=(), dtype=float32)\ntf.Tensor(8769156.0, shape=(), dtype=float32)\ntf.Tensor(8706610.0, shape=(), dtype=float32)\ntf.Tensor(8646141.0, shape=(), dtype=float32)\ntf.Tensor(8583266.0, shape=(), dtype=float32)\ntf.Tensor(8518188.0, shape=(), dtype=float32)\ntf.Tensor(8453551.0, shape=(), dtype=float32)\ntf.Tensor(8390779.0, shape=(), dtype=float32)\ntf.Tensor(8329482.0, shape=(), dtype=float32)\ntf.Tensor(8267711.5, shape=(), dtype=float32)\ntf.Tensor(8207276.0, shape=(), dtype=float32)\ntf.Tensor(8150688.0, shape=(), dtype=float32)\ntf.Tensor(8099657.0, shape=(), dtype=float32)\ntf.Tensor(8049661.5, shape=(), dtype=float32)\ntf.Tensor(7997398.0, shape=(), dtype=float32)\ntf.Tensor(7944768.0, shape=(), dtype=float32)\ntf.Tensor(7894435.0, shape=(), dtype=float32)\ntf.Tensor(7848761.0, shape=(), dtype=float32)\ntf.Tensor(7804045.0, shape=(), dtype=float32)\ntf.Tensor(7756587.0, shape=(), dtype=float32)\ntf.Tensor(7705750.0, shape=(), dtype=float32)\ntf.Tensor(7651803.0, shape=(), dtype=float32)\ntf.Tensor(7600600.5, shape=(), dtype=float32)\ntf.Tensor(7552283.5, shape=(), dtype=float32)\ntf.Tensor(7506373.0, shape=(), dtype=float32)\ntf.Tensor(7461972.5, shape=(), dtype=float32)\ntf.Tensor(7416300.0, shape=(), dtype=float32)\ntf.Tensor(7372643.0, shape=(), dtype=float32)\ntf.Tensor(7331797.0, shape=(), dtype=float32)\ntf.Tensor(7290330.0, shape=(), dtype=float32)\ntf.Tensor(7247758.0, shape=(), dtype=float32)\ntf.Tensor(7204652.0, shape=(), dtype=float32)\ntf.Tensor(7162183.5, shape=(), dtype=float32)\ntf.Tensor(7122622.5, shape=(), dtype=float32)\ntf.Tensor(7085788.0, shape=(), dtype=float32)\ntf.Tensor(7047748.0, shape=(), dtype=float32)\ntf.Tensor(7007902.0, shape=(), dtype=float32)\ntf.Tensor(6967470.0, shape=(), dtype=float32)\ntf.Tensor(6927844.0, shape=(), dtype=float32)\ntf.Tensor(6890170.5, shape=(), dtype=float32)\ntf.Tensor(6854781.0, shape=(), dtype=float32)\ntf.Tensor(6819279.0, shape=(), dtype=float32)\ntf.Tensor(6784834.0, shape=(), dtype=float32)\ntf.Tensor(6751367.0, shape=(), dtype=float32)\ntf.Tensor(6720046.0, shape=(), dtype=float32)\ntf.Tensor(6690089.0, shape=(), dtype=float32)\ntf.Tensor(6657547.0, shape=(), dtype=float32)\ntf.Tensor(6624106.5, shape=(), dtype=float32)\ntf.Tensor(6594121.0, shape=(), dtype=float32)\ntf.Tensor(6566351.0, shape=(), dtype=float32)\ntf.Tensor(6539158.5, shape=(), dtype=float32)\ntf.Tensor(6511577.0, shape=(), dtype=float32)\ntf.Tensor(6483562.0, shape=(), dtype=float32)\ntf.Tensor(6455001.0, shape=(), dtype=float32)\ntf.Tensor(6427295.0, shape=(), dtype=float32)\ntf.Tensor(6399779.0, shape=(), dtype=float32)\ntf.Tensor(6371958.0, shape=(), dtype=float32)\ntf.Tensor(6343680.0, shape=(), dtype=float32)\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-6f07bbbe251a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m# print('Step:{}/100'.format(m))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mgrad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstyle_gram\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstyle_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontent_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcontent_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m1e-3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_by_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_value_min\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_value_max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-85-ccd6728d2fd5>\u001b[0m in \u001b[0;36mgradients\u001b[1;34m(StyleTransModel, gen_image, style_gram, content_outputs, weights, alpha, beta)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mgradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStyleTransModel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgen_image\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstyle_gram\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontent_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0moutput_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStyleTransModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;31m# loss = 0.5*tf.reduce_sum(tf.square(tf.subtract(output_content,output_gen)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mcont_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcontent_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_gen\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcontent_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CoreEnv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    983\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    984\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_auto_cast_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_dtype_object\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 985\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    986\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    987\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-86-a45fefcf866c>\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mprocessed_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg19\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprocessed_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CoreEnv\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\vgg19.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_export\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'keras.applications.vgg19.preprocess_input'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 235\u001b[1;33m   return imagenet_utils.preprocess_input(\n\u001b[0m\u001b[0;32m    236\u001b[0m       x, data_format=data_format, mode='caffe')\n\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CoreEnv\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mpreprocess_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    116\u001b[0m         x, data_format=data_format, mode=mode)\n\u001b[0;32m    117\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 118\u001b[1;33m     return _preprocess_symbolic_input(\n\u001b[0m\u001b[0;32m    119\u001b[0m         x, data_format=data_format, mode=mode)\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CoreEnv\\lib\\site-packages\\tensorflow\\python\\keras\\applications\\imagenet_utils.py\u001b[0m in \u001b[0;36m_preprocess_symbolic_input\u001b[1;34m(x, data_format, mode)\u001b[0m\n\u001b[0;32m    288\u001b[0m         x, backend.cast(mean_tensor, backend.dtype(x)), data_format=data_format)\n\u001b[0;32m    289\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 290\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    291\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mstd\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CoreEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CoreEnv\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(x, bias, data_format)\u001b[0m\n\u001b[0;32m   5771\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5772\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NCHW'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5773\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias_add\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'NHWC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5774\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5775\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'channels_first'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CoreEnv\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m       \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CoreEnv\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m   3364\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3366\u001b[1;33m       return gen_nn_ops.bias_add(\n\u001b[0m\u001b[0;32m   3367\u001b[0m           value, bias, data_format=data_format, name=name)\n\u001b[0;32m   3368\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\CoreEnv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\u001b[0m in \u001b[0;36mbias_add\u001b[1;34m(value, bias, data_format, name)\u001b[0m\n\u001b[0;32m    674\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    677\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"BiasAdd\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m         tld.op_callbacks, value, bias, \"data_format\", data_format)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch = 10\n",
    "steps = 100\n",
    "\n",
    "for n in range(epoch):\n",
    "    print('Epoch:{}/10\\n'.format(n))\n",
    "    # display.display(PIL.Image.fromarray(np.array(X[0]*255, dtype = np.uint8)))\n",
    "    for m in range(steps):\n",
    "        # print('Step:{}/100'.format(m))\n",
    "        grad = gradients(model,X,style_gram=style_gram,content_outputs=content_outputs,weights=weights, alpha= 1e-3, beta = 10)\n",
    "        optimizer.apply_gradients(grads_and_vars=[(grad,X)])\n",
    "        X.assign(tf.clip_by_value(X, clip_value_min=0.0, clip_value_max=1.0),read_value=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}